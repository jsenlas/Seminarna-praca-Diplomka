\chapter{Theoretical introduction}


\section{Optical reflectometry}

Optical reflectometry is used for measurements of optical cables' properties; it is capable of detecting defects, joints, breaks, or other damage and their location on the wire. It is the basis for \ac{generalotdr} or \ac{ofdr} and other optical sensors such as \ac{das}. A~pulse of light is sent from the source, such as a light-emitting diode (LED) or a laser diode (LD). The light travels from the source through the optical fiber in pulses and is reflected from the other side of the wire, through connections, breaks, damage, or imperfections in the material. All of these create some backscattering toward the light source. Rayleigh, Brillouin, and Raman scattering are all different kinds of scattering happening in the fiber \cite{progress}. 

\subsection{OTDR}

\ac{otdr} is the most widely used method. When a strain is applied to the fiber, it causes phase-shift changes in the light signal. Provides high sensitivity, resolution, and high sampling rates in the frequency range between hertz and kilohertz. \ac{otdr} has limitations in measuring slowly changing effects and noise components.

% \subsection{(\acs{otdr})}   %\acl{otdr} 

% \acl{otdr} 

%https://www.flukenetworks.com/expertise/learn-about/otdr


\subsection{OFDR}

\ac{ofdr} analyzes interference of signal between the initial signal and the backscattered signal but focuses on the frequency scan. It requires a highly tunable laser diode as a~source of light. The signal given by \ac{ofdr} contains frequency information that can be processed with the Fourier transformation, and the output would be the position of the reflective elements along the fiber length. There are also other methods to measure light properties such as \textit{C-OFDR} - coherent version of OFDR using light with the frequency with linear dependency but having problems with high noise levels, and \textit{DSS} - Mandelstam-Brillouin \cite{kislov_das_newparadigm}.


\section{Distributed Acoustic Sensing}

Implementation of \ac{das} system is usually done by \ac{generalotdr}, \ac{ofdr}, or analysis of other light properties such as polarization and backscatter correlation. \ac{das} allows the measurement of thousands of points on an optical wire without the need to cut the wire or have multiple sensors distributed along the wire. The measurement mechanism is based on optical reflectometry the same as in DTS (distributed temperature sensing), which is a variant of \ac{generalotdr}. Measurement is based on the sending of pulses of light into the optical fiber. The fiber creates a small light scattering (e. g. Rayleigh scattering) in the glass that travels back to the sensing unit (on the same side as the light source), which can be interpreted on the basis of the time of arrival as position on the wire. Backscattering light from the optical fiber segment is detected at the light source and has changes in amplitude or phase, which means that the fiber wire segment is affected in some way. \ac{das} is used in a wide range of applications, from locating seismic activity, locating trains along the train tracks, as a~gyroscope or an accelerometer or even as a~microphone \cite{WangYu2017RDVM}, \cite{kislov_das_newparadigm}.

\ac{das} uses optical fiber since many sensors are capable of detecting vibrations along the fiber \cite{gabai}. These sensors allow for the measurement of acoustic properties (frequency, amplitude, and phase) \cite{WangYu2017RDVM}. 

There are two types of optical fiber sensors:
\begin{enumerate}
    \item Point - These sensors measure only at the location of the transducer
    \item Distributed - The sensing element is the optical wire and can measure at many points along the optical wire. One of the great benefits of this approach is the possibility of using existing telecommunication infrastructure to build the sensing network.
\end{enumerate}

% \subsection{Raleigh scattering}

% For a given optical frequency, sensors based on Raleigh scattering can detect the intensity, phase, and polarization of light.   
% %TODO

\section{iDAS}

The distributed acoustic sensor is a~new addition to distributed optical fiber sensors used in the energy industry and can be used in many applications, for example, in detecting seismic activity. iDAS (intelligent distributed acoustic sensor) is one type of DAS sensor. One of the applications of this sensor is to record an acoustic signal. To determine the signal fidelity, a certain part of the wire is subjected to a known signal, e.g. sine wave. A measurement is made, and the result is compared with the existing recording device. The result suggests that iDAS has very good signal properties. The measured signal shows that almost no measurable crosstalk is exhibited between the two sensing channels on the wire.

The maximum sampling rate can be calculated from the speed of light that travels in glass at a speed of about \qty{200000}{\km/\s} which corresponds to approximately \qty{10}{\kHz} for \qty{10}{\km} long wire \cite{WangYu2017RDVM}.

% 10 kHz == 10 km, 1 kHz == 100 km [doplnit vzorcek]

\begin{itemize}
    \item Acoustic bandwidth
    \item Dynamic range - \qty{120}{\dB} as reported in \cite{dasseismic}
    \item Spatial resolution - about \qty{1}{\m} to \qty{10}{\m}, but up to \qty{25}{\cm} is possible
    \item Measurement range - The fiber length can be anywhere from a few hundred meters to more than \qty{100}{\km}.
\end{itemize}



\section{OptaSense ODH-F}

Data used in this project were obtained from \textit{OptaSense ODHF Distributed Acoustic Sensing Interrogator}\footnote{\url{https://www.optasense.com/technology/odhf/}}. This device is capable of monitoring optical fiber up to \qty{50}{\km} long (in qualitative mode). It is used for in-well flow monitoring, pipeline integrity management, and border security. OptaSense comes with \textit{DxS Visualization Software} which is capable of analyzing and processing output data from the unit. It can show the signal spectrum in a waterfall graph and create analysis, process the signal using \ac{fft}, and extract data to \verb|.wav| format. It has the limitation that it can only run in the Windows ecosystem and is proprietary software, so scientists cannot really change how they work with the data or how it is displayed.


\subsection{HDF5 file format}

In this project, the output of the DAS system is in \ac{hdf}. Data from the \ac{das} sensor is collected on the server and saved in \ac{hdf} file. \ac{hdf} creates a model for managing and storing data. The HDF Group\footnote{\url{https://www.hdfgroup.org/}} is the maintainer of the software package. Specifically, the \ac{hdf} format is used to store data, but it is only one of the three parts that make up the \ac{hdf} model. Parts of the \ac{hdf} model are:

\begin{itemize}
    \item File format - files ending with .h5
    \item Data model - specifies the building blocks of the \ac{hdf} file format
    \item Software - libraries, tools, APIs
\end{itemize}

\bigskip

\ac{hdf} data model has a folder-like organization, where the folders are called \textit{groups}. This model specifies the format in which the data are stored in the form of \ac{adm}, which specifies the organization of the data and the types of data. Every \ac{hdf} file has to have a~root group \textit{``/''}. Working with groups is very similar to directories on Linux systems; see Section \ref{dir:filestructure}. Each group can have \textit{datasets} that contain raw data, attributes, data types, and other objects. \ac{hdf} file can also specify links to other libraries and tools such as compression and filtering.

\bigskip
HSDF5 dataset has connections with other HDF5 objects:

\begin{itemize}
    \item \textbf{attributes} - named data object containing the name and the value
    \item \textbf{datatypes}:
    \begin{itemize}
        \item Atomic datatypes - time, string, integer, float.
        \item Composite datatypes - array, enumeration, compound, variable length.
    \end{itemize}
    \item \textbf{data} - data itself, for example, the result of measurement.
    \item \textbf{dataspace} - the shape of the data.
\end{itemize}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pdf/hdf5_file_structure.pdf}
    \caption{Basic HDF5 file structure}
    \label{fig:filestructure}
\end{figure}

\newpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation and software design}

\section{Program implementation of HDF5 to WAV}\label{lab:hdftowav}

The goal of this project is to create an application for reading data from the \ac{das} system and converting the data to the \verb|.wav| audio file format.

For the implementation of this application, the Python\footnote{\url{https://www.python.org/}} programming language was chosen. Python is a~great language for scientific use, data visualization, and graph plotting, which is the goal. The biggest advantage comes from the availability of scientific libraries. The opening of \verb |.h5| files is done with \verb|h5py| library\footnote{\url{https://www.h5py.org/}}. For working with dataset data types \verb|numpy|\footnote{\url{https://numpy.org/}} library is used. The function for interpolating arrays to a~certain range is also used \verb|interp|. Lastly, to convert the signal data to \verb|.wav| audio format \verb|scipy| library is used specifically \verb|io| module function \verb|wavfile|. To read all options and input arguments, the \verb|argparse| library is used\footnote{\url{https://docs.python.org/3/library/argparse.html}}.   

\subsection{Reading HDF5 file}\label{sec:readhdf}

The sample file recorded in the OptaSense ODH-F is in HDF5 file format. As \ac{hdf} files have a~user-defined structure on the application layer and in the binary form it is hard to say what is actually in the file. To better understand the contents of the \verb|.h5| file, \verb|h5dump| was performed and a conversion to JSON\footnote{\url{https://www.json.org/json-en.html}} was also performed by the \verb|h5tojson| program\footnote{\url{https://hdf5-json.readthedocs.io/en/latest/tools/h5json.html}}. The JSON file is quite large in size - the original HDF5 file is only \qty{52,7}{MB} and the JSON file is \qty{946,6}{MB}. The dump text file is half the size and provides the same information, but the datasets are harder to understand, but the whole file is only half the size of the JSON file at ``only'' \qty{420}{MB}. The JSON format is much easier to read. The structure of the file is divided into 3 parts:

\begin{itemize}
    \item \textit{apiVersion} - 1.1.1 version of API
    \item \textit{datasets} - Contain all the datasets organized by their UUID\footnote{Universally unique identifier} that are defined in the groups section. There is also an \textit{alias} that is in the format of a Unix-based system path, for example, \verb|"/Acquisition/Raw[0]/Custom/SampleCount"|. There are also other properties that define the shape and type of stored data. In this case, the properties are shown in the table \ref{tab:file_details}.
    \item \textit{groups} - Groups are named by a UUID. The group object has:
        \begin{itemize}
            \item \textit{alias} - Unix-like name; the first is root ``/'' group
            \item \textit{attributes} - define the type, name, and shape of the value of the attribute which is a string \verb|979bb2ac-99bf-4cb5-b410-5c16cd7872dc|
            \item \textit{links} - links to other groups that create a treelike structure. The link object contains the class of a link (e.g. H5L\_TYPE\_HARD for hard link), the \textit{collection} property telling that it is a group and the name of the group. The group object also contains other important metadata, such as measurement settings. All important details are given in the table \ref{tab:file_details}
        \end{itemize}
\end{itemize}

There is a~library for reading \ac{hdf} files using Python called \verb|h5py|. To read the contents of the file, a~function was created called \verb|get_dataset_path()| which recursively looks for all groups, according to their name provided by the \verb|.keys()| method, in the dataset. The result of this function is propagated through recursion and saved in Python \verb|set()| built-in type. The user can then choose which one is the right dataset to use because there is probably more than one dataset. The user can save the string and use it as an argument when calling the program. This saves time in searching for the contents of the file. 

This is the data structure of the DAS file from the OptaSense Interrogator:

\bigskip
DAS output file structure in \ac{hdf} format
{\small
%
\label{dir:filestructure}
\dirtree{%.
.1 /\DTcomment{root}.
.2 Acquisition\DTcomment{Recorded data}.
.3 Custom\DTcomment{Empty}.
.3 Raw[0]\DTcomment{HDF5 group (3 members)}.
.4 Custom\DTcomment{HDF5 group (1 members)}.
.5 SampleCount\DTcomment{HDF5 dataset, shape (332032,), type "<i8">}.
.4 RawData[0]\DTcomment{HDF5 dataset, shape (100, 332032), type "<i2">}.
.4 RawDataTime\DTcomment{HDF5 dataset, shape (332032,), type "<i8">}.
}
}
\bigskip

The type of explanation in \ref{dir:filestructure} is \verb|i8|, which is \verb|numberpy.int64|. \verb|SampleCount| contains numbering of all samples, \verb|RawDataTime| contains time, and \verb|RawData[0]| contains useful sensor data that we need to read in the next steps; see \ref{sec:data_processing}. More details are provided in Table \ref{tab:file_details}.

All important HDF5 attributes are shown in the table \ref{tab:file_details}, it contains metadata information about the datasets, data dimensions, number of channels, kinds of filters used, time information, length of pulses, laser wavelength, and more. Some properties can be derived from those in the table. The capture duration can be calculated from the start and end of the capture, which is \qty{10,376}{\second}.

\subsection{Data processing} \label{sec:data_processing}

The useful data have 100 channels with \textit{N} samples, in this example \qty{332032}{samples} saved in \verb|/Acquisition/Raw[0]/RawData[0]|, see the file structure in \ref{dir:filestructure}. The function \verb|scipy.io.wavfile.write()| is used to save samples to a file and the data need some more processing before the function can be called. After the data are read from the file, it is saved into \verb|samples| variable of type \verb|numpy.array| it is then processed in 4 steps as preparation for saving into \verb|.wav| file. The steps are:

\begin{enumerate}
    \item \textbf{Channel selection} - only channel one can be selected.
    \item \textbf{Data interpolation} - The original data have a bad value range from -24838 to -30758, triggering an exception when writing the data into a \verb|.wav| file. The \verb|numpy.interp()|\footnote{\url{https://numpy.org/doc/stable/reference/generated/numpy.interp.html}} function interpolates the data into the range of the maximum and minimum values specified in this case by the \qty{16}{bit} PCM\footnote{Pulse Code Modulation}, which can be written to WAV file by \verb|wavfile| module.
    \item \textbf{Resampling} - as the data are recorded at a certain sampling frequency, in this case, \qty{10}{\kHz}, resampling by the function \verb|scipy.signal.resample() |\footnote{\url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html}} is necessary. The right number of samples is calculated by the formula \ref{formula:sampling}.
    \item \textbf{Retyping} - the resampled data need to be in the correct format and since the interpolation was done in the range of \verb|int16| the output type of choice is the same \verb|samples.astype(np.int16)|.
\end{enumerate}

\begin{equation}
    \label{formula:sampling}
    numSamples = \frac{44100}{fs.len(samples)}
\end{equation}


\begin{table}[]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Data type} & \textbf{Minimum value} & \textbf{Maximum value} & \textbf{WAV format} \\
    \hline
    float32 & -1.0 & +1.0 & 32-bit floating-point \\ \hline
    int32 & -2147483648 & +2147483647 & 32-bit PCM \\ \hline
    int16 & -32768 & +32767 & 16-bit PCM \\ \hline
    uint8 & 0 & 255 & 8-bit PCM \\
    \hline
    \end{tabular}
    \caption{WAV compatible types}
    \label{tab:my_label}
\end{table}




\newpage

\section{Software design}


There are many ways to implement data visualization, but it is hard to choose the right solution, the right programming language, or a framework, so this chapter first provides information on what this application should do. Second, it provides a study of the existing OptaSense software and other solutions accessible from the internet. Lastly, it explains the software design decisions for the implementation of this data visualization.

\subsection{Usecases}\label{lab:usecases}

The task is to fulfill the requirements and basic usage as can be seen in the use case figure \ref{fig:usecase}. They need to see and view what is happening in their perimeter on their screen. For this purpose, the best data visualization is a waterfall graph, similar to a spectrogram, displayed as the main element. It should have an editable color map to change the sensitivity. The waterfall view should be a fully animated waterfall graph and ideally display real-time data on the screen, similar to the OS6 system; see Section \ref{sec:ossix}. In addition, the user should perform selection and zoom on the waterfall graph. The user should be able to edit properties of the graph, like changing the data range and choosing the channels he or she wants to see. The user should be able to export the data to a WAV file by clicking a button and then viewing and playing the audio file. There should also be a waveform display available to show the playing data.

\begin{figure}[h]
    \centering
    \includegraphics{pdf/usecase.drawio.pdf}
    \caption{Application usecases}
    \label{fig:usecase}
\end{figure}

\subsection{Application requirements}

From the use cases in Section \ref{lab:usecases} it is understandable that the application should have certain features. Apart from the given use cases, there are other important requirements:

\begin{itemize}
    \item Support for real-time data plotting - graph updates or animation; fetching the data online from the OptaSense Interrogator and displaying it in real-time
    \item Multiplatform - the application should run on any device and still support all features
    \item Data processing - subsampling data to save data throughput
    \item Plot editing and animation - changing plot properties
    \item Reading offline data - possibility to read local files or upload files into the application
    % \item 
\end{itemize}

% There is the option to create an application running on the operating system

\begin{figure}[h]
    \centering
    \includegraphics{pdf/simple_application.drawio.pdf}
    \caption{Data flow in the application - reading the data then processing the data and displaying it (optionally) edit the view}
    \label{fig:dataflow}
\end{figure}

It is necessary to choose the right programming tools to satisfy all features. The right way to find the right solution in programming is to \textit{divide and conquer}. This means finding all the pieces that will make the application. First, there must be an idea of what will happen with the data. Firstly, it has to be read, processed, and then displayed, the optional step is to edit the data or change the view; this data flow can be seen in Figure \ref{fig:dataflow}. 

% Multiplatform requirement removes many options - like creating a simple GUI application, as creating a multiplatform high-performance application is quite a feat and is beyond this project. So the result is making a web site and display  there is one solution either using 

From the data flow application, an overview can be made for a web application, as can be seen in Figure \ref{fig:app_overview}. The overview illustrates what parts the application will have. The back-end or server application will be responsible for reading HDF5 files and processing data. It will provide some form of interface or API for the client application to fetch\footnote{\url{https://developer.mozilla.org/en-US/docs/Web/API/Fetch\_API}} the data. On the client side, the client has to be able to create visualizations of the data and provide a user interface to change application properties.

\begin{figure}
    \centering
    \includegraphics{pdf/appstack_general.drawio.pdf}
    \caption{Application overview. The server reads the data from the data storage and sends it to the client application, where it is shown to the user}
    \label{fig:app_overview}
\end{figure}

\section{Existing technology for data visualization}

This section focuses on data processing and visualization using existing software for visualizing scientific data. First is OptaSense OS6 software which is a purpose-made solution for OptaSense devices. Next is the h5web library, written in React, which creates a web page for visualizing the content of HDF5 files.

\subsection{OptaSense OS6}\label{sec:ossix}

The OptaSense company provides visualization software for their devices called OptaSense OS6\footnote{\url{https://www.optasense.com/technology/os/}}. It runs only on the Windows operating system. OS6 provides features for monitoring certain areas or land, for example, a compound or an industrial building. This product is tailor-made for OptaSense devices by the OptaSense company. This system has only one window for everything. The main view is the monitored area; the background picture is the aerial view of the whole monitored space, as can be seen in the picture \ref{fig:ossix}. The user can open the sidebar on the right side. The sidebar provides multiple different options:

\begin{itemize}
    \item \textbf{Spectrogram} - Raw data visualization.
    \item \textbf{Alerts} - When an action is detected along the wire, it is logged.
    \item \textbf{Notifications} -  Notifications about system state.
    \item \textbf{System status} - Overview of all OptaSense units and their state.
\end{itemize}

There is also a feature that takes raw data from interrogator units and processes them using machine learning. In this way, different actions are detected and categorized into different types of alerts, such as walking, driving cars, etc. In addition, the user can see the activities that were detected and triggered in the area overview with live monitoring and a timeline at the top of the screen. To easily look at different locations or start a new view, there is a feature \textit{type to search} that lets the user start a search by typing into the view. For example, the user starts writing ``water...'' as a waterfall, and the program will look for this feature and open the waterfall visualization window. OS6 saves all detected activities, which can be shown in the \textit{Historic timeline} window, which shows all alerts that occurred during a specified time range. The animations look very nice, although some of them look a bit choppy mostly when showing activities on top of the waterfall view. 

Anyway, it is proof that it is possible to create a real-time data visualization from the DAS system. It lacks one important step, which is the ability to be used not only on Windows machines and to be truly multiplatform.

\begin{figure}[]
    \centering
    \includegraphics[width=\linewidth]{obrazky/OSsix.png}
    \caption{OptaSense OS6 visualization software \cite{ytossix}}
    \label{fig:ossix}
\end{figure}

\subsection{h5web}

The \verb|h5web|\footnote{\url{https://h5web.panosc.eu/}} library is a set of components written in React\footnote{React is a JavaScript library used to create interactive user interface \url{https://reactjs.org/}}. H5web uses existing HDF5 libraries, such as h5wasm (reading HDF5 files in the browser) and h5grove (server for accessing HDF5 files). It displays the contents of HDF5 file, as well as shows different graphs according to the input from the user. From the presentation of the library by its developer it is safe to say that although it provides the necessary equipment for opening HDF5 files elegantly and provides advanced graphing techniques it lacks the ability to receive the data and display them in real-time. For this purpose, the library would need to add support by creating a new React component capable of such behavior, but it is possible.

\subsection{Backend}

The purpose of the backend part of the application is to read, process, and send the data to the client part of the application, as can be seen in Figure \ref{fig:app_overview}. Reading the HDF5 data is done as explained in Section \ref{sec:readhdf}.

\subsubsection{REST servers}

There is a wide range of REST server implementations; HDF Group provides documentation for its RESTful API\footnote{\url{https://support.hdfgroup.org/pubs/papers/RESTful\_HDF5.pdf}}. They have prepared a few RESTful server implementations for their data format. There are many more implementations of REST servers, such as the Python Simple HTTP server. Here is a list of some possible implementations \cite{hdfrest}:

\begin{itemize}
    \item \emph{h5serv} - REST-based service to access HDF5 data written in Python (HDF5 Group).
    \item \emph{HSDS} (Highly Scalable Data Service)\footnote{\url{https://github.com/HDFGroup/hsds}} - Python implementation of the REST-based service to access HDF5 data stores. Data can be stored in the POSIX file system or using object-based storage such as AWS S3. It can run in a Docker as a single machine or on a Kubernetes cluster.
    \item \emph{hdf-rest-api}\footnote{https://github.com/HDFGroup/hdf-rest-api} - is HDF5 REST API that provides CRUD support (create, read, update, and delete) for all HDF5 objects.
    \item \emph{h5grove} - Backend service written in Python providing access to HDF5 file content.
    \item \emph{http.server} - Python implementation of a simple HTTP server. However, this is better used only for testing purposes when accessing local files.
\end{itemize}

\subsubsection{WebSockets}

WebSockets (or WebSocket API) enable two-way communication over TCP. It was standardized by IEFT in RFC6455. WebSocket protocol is supported by all modern browsers. The communication starts with an HTTP-compatible handshake, so only one socket can be used to communicate with the server. There are also other header types available for different uses. The server responds with an HTTP Upgrade, the connection is established, and bidirectional communication can begin. Communication closes when either side decides to close the connection and starts closing the handshake. The other side responds with a \textit{Close frame} message and the connection is closed. The protocol is trying to be frame-based as is HTTP but also frame-based as little as possible, just to make sure that it can use the HTTP interface for communication; otherwise it tries to be as minimalist as possible. The authors of the WebSocket protocol wanted it to be low-level and as close to TCP as possible \cite{websock}. WebSockets have an implementation in the Python programming language called \verb|websockets|\footnote{https://pypi.org/project/websockets/}.

\begin{figure}[h]
    \centering
    \includegraphics{pdf/websocket.drawio.pdf}
    \caption{WebSocket handshake, communication, and connection close diagram.}
    \label{fig:websocket}
\end{figure}

% \subsubsection{Processing data}\label{lab:processingdata}

% The data read from the file is in 

% %TODO







\subsection{Frontend}

% \subsubsection{WebGL}

% WebGL is a cross-platform web standard for 3D graphics API based on OpneGL, that is rendering into HTML \verb|<canvas>| element. It supports 
% https://github.com/bastibe/WebGL-Spectrogram


\subsubsection{Svelte}

Svelte is a component framework written in JavaScript, using a new approach to building web applications. Instead of looking for differences in virtual DOMs as React does, which is done in the browser and consumes quite a lot of resources, Svelte does everything at the compilation stage. The output of the compilation is a JavaScript file \verb|bundle.js|, which contains all the necessary code to run the web application or better said, it manipulates the DOM directly. The result is a fast and reactive web page, it also saves resources, and the code can be run on small devices like handheld devices. Web development is also very enjoyable because compilation does not take long and the result of changes can be visible immediately. Svelte also integrates CSS stylesheets into the components. The structure of a Svelte component consists of three parts - JavaScript code tag \verb|<script>| a style tag \verb|<style>| and other HTML elements. 

Svelte is capable of client-side rendering and server-side rendering, but it does not provide more advanced features like page routing. For this purpose, the Svelte team created SvelteKit, which is a~framework for building web applications and allows page routing. Routing is folder-based - the developer creates routing by creating a folder and file structure.

\begin{verbatim}
src/routes/about/+page.svelte <=> /about
src/routes/about.svelte <=> /about
\end{verbatim}

Svelte has been changing and has become a Vite \footnote{\url{https://vitejs.dev}} plugin. Vite provides fast development experience by running a development server, in the case of Svelte - Hot Module Replacement (HMR)\footnote{\url{https://vitejs.dev/guide/features.html\#hot-module-replacement}}. This way, every change made during development can be immediately seen in the browser without reloading the page, which makes development much faster and more enjoyable. It is necessary to say that Svelte is still in development and although it is now at version 3 it is possible that it will change in the future. 

When fetching the data from the server, it is good practice to move this functionality to a Svelte Store. The Svelte store is a separate JavaScript file that can be accessed from multiple components. From a programming point of view, a store is an object with a \verb|subscribe()| function. An example of a WebSocket implementation in Svelte can be the Svelte component library \textit{svelte-websocket-store}\footnote{\url{https://github.com/arlac77/svelte-websocket-store}}.

\subsection{Real-time capabilities}

The data bandwidth (the amount of data necessary to be sent from the server side to the client side) of the application is the biggest factor. The OptaSense Interrogator can produce quite a lot of data, but if it is saved in an HDF5 file, it is quite small. As discussed in Section \ref{sec:readhdf}, a \qty{10}{\second} file produces around \qty{52}{MB} of data. When this data is transformed into text form, it has only \qty{420}{MB} and when transformed into JSON, it has \qty{946}{MB} as the data are read at \ac{SPS} \qty{10}{kSPS}\footnote{\ac{SPS}}. Data will be displayed on a display with standard resolution and cannot display \qty{10000}{SPS} on a small part of the display. Data processing is necessary for this purpose. 

% \subsubsection{Data processing}

% Data processing can be done on the server side or in the browser. As the browser will be busy redrawing waterfall visualization it is better to do data preprocessing on the server side. Server-side preprocessing will also save bandwidth as the data will be significantly filtered. 

% Sending data in the form of REST requests and responses can be possible but it is really useful only when sending a small HDF5 file as a whole not as a stream of data and although h5grove backend provides the ability to read sections of the data set for  The respective bandwidth would be \qty{}{}



% %TODO


 % The JSON file is quite large - the original HDF5 file is only \qty{52,7}{MB} and the JSON file is \qty{946,6}{MB}. The dump text file is half the size and provides the same information, but the datasets are harder to understand, but the whole file is only half the size of the JSON file at ``only'' \qty{420}{MB}. The JSON format is much easier to read. The structure of the file is divided into three parts:

\subsection{Software design for DAS data visualization}

As we discussed in Section \ref{sec:ossix}, it is possible to create such software to display the data in real time. The application was a native Windows application, and the requirement for this application was to be able to run on multiple platforms. The chosen platform is the Python backend, opening files, processing the data, and sending the data into the client application using Svelte. The backend will process the data as explained in \ref{lab:processingdata}. The waterfall graph will be an HTML Canvas element that displays the data in real-time, redrawing itself as the data arrive at the browser. For ease of displaying the data in Canvas, D3js will be used. D3 will, for example, apply a color map to the correct scale according to the data. The user interface written in Svelte will also have inputs to change the properties of the visualization so that the user can select specific channels from the data, choose subsampling effect properties, cutting the frequency range. The ability to export the data to a WAV file will also be implemented the same way as done in Section \ref{lab:hdftowav}.

\begin{figure}
    \centering
    \includegraphics{obrazky/appstack.drawio.pdf}
    \caption{Application overview}
    \label{fig:app_overview}
\end{figure}

\subsection{Prototype}

This work aims to design an application to visualize HDF5 data acquired from the OptaSense Interrogator. For this purpose, Svelte was used mainly for its high performance, thanks to efficient code created at compilation. This is a prototype, so it is not a working application. It is only to show how this application will look in the end. The final version of the application will also use Svelte. The prototype uses Flowbite components\footnote{\url{https://flowbite-svelte.com/}} as they make it easy to create stylized web pages. The web page is divided into Svelte components. The main component is the waterfall graph on the left side of the screen and the control panel on the right side. Layout is done with svelte-layouts\footnote{\url{https://www.npmjs.com/package/svelte-layouts}} package. 

Uploading files into the browser using REST API was also tested. Python's \verb|http.server| was used as the backend. When fetching files into a browser from local storage using HTTP, it is necessary to allow Cross-Origin Resource Sharing (CORS) because browsers restrict this feature for security reasons. Some resources like CSS, Web Fonts, and WebGL textures have enabled CORS. For sending HDF5 files to the browser, a special HTTP header has to be added on the server side. Without this feature, the browser would throw an error into the JavaScript console.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{obrazky/svelte_prototype.png}
    \caption{Prototype of DAS visualization application}
    \label{fig:prototypesvelte}
\end{figure}
